{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Python environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from openpyxl import load_workbook\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "import math\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# hack to get relative imports to work\n",
    "import sys\n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path.\n",
    "from utils import utils\n",
    "from utils import venn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set plot settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET PLOTTING SETTINGS\n",
    "SMALL_SIZE = 16\n",
    "MEDIUM_SIZE = 20\n",
    "BIGGER_SIZE = 24\n",
    "BIGGEST_SIZE = 28\n",
    "\n",
    "plt.rc('font', size=MEDIUM_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=MEDIUM_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../Data/df_ORF_condition_normalized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare GEM, MACE & maxPeak scores to set thresholds\n",
    "\n",
    "## Minimal score of targets shown by both GEM and MACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [1,0.005] # initial thresholds for: GEM, MACE\n",
    "\n",
    "experiments = ['Fkh1 log','Fkh1 stat','Fkh2 log','Fkh2 stat']\n",
    "for exp in experiments:\n",
    "    print(df[(df['GEM '+exp] >= t[0]) & (df['MACE '+exp] <= t[1])]['maxPeak_AD_12 '+exp].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set thresholds\n",
    "Heuristically determined from the score comparisons.\n",
    "\n",
    "We set the maxPeak score based on the lowest score obtained by genes predicted by GEM and MACE using the thresholds of 1 and 0.005."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [1,1,0.005] # thresholds for: maxPeak, GEM, MACE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score comparison plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = ['Fkh1 log','Fkh1 stat','Fkh2 log','Fkh2 stat']\n",
    "\n",
    "fig = plt.figure(figsize=(20,12))\n",
    "ax1 = plt.subplot2grid((100, 100), (0, 0), rowspan=44, colspan=45)\n",
    "ax2 = plt.subplot2grid((100, 100), (0, 55), rowspan=44, colspan=45)\n",
    "ax3 = plt.subplot2grid((100, 100), (56, 0), rowspan=44, colspan=45)\n",
    "ax4 = plt.subplot2grid((100, 100), (56, 55), rowspan=44, colspan=45)\n",
    "axes = [ax1,ax2,ax3,ax4]\n",
    "\n",
    "for k in range(len(experiments)):\n",
    "    ax = axes[k]\n",
    "    exp = experiments[k]\n",
    "    \n",
    "    df_targets = df[['maxPeak_AD_12 '+exp, 'GEM '+exp , 'MACE '+exp]]\n",
    "        \n",
    "    df_targets_gem = df_targets[df_targets['GEM '+exp] >= t[1]]\n",
    "    df_targets_notgem = df_targets[(df_targets['GEM '+exp] < t[1]) | (df_targets['GEM '+exp].isnull())]\n",
    "\n",
    "    x1 = df_targets_gem['MACE '+exp]\n",
    "    y1 = df_targets_gem['maxPeak_AD_12 '+exp]\n",
    "        \n",
    "    x2 = df_targets_notgem['MACE '+exp]\n",
    "    y2 = df_targets_notgem['maxPeak_AD_12 '+exp]\n",
    "    \n",
    "    h2 = ax.scatter(x2,y2,c=['red']*len(x2),alpha=0.5)\n",
    "    h1 = ax.scatter(x1,y1,c=['blue']*len(x1),alpha=0.5)\n",
    "\n",
    "    ax.plot(np.linspace(0,0.01,100), [t[0]]*100,'k-.')\n",
    "    ymax = 1.15*max(df_targets['maxPeak_AD_12 '+exp].values)\n",
    "    ax.plot([t[2]]*100, np.linspace(0,ymax,100),'k-.')\n",
    "    \n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlim(0.0001, 0.01)\n",
    "    ax.set_xticks([0.0001, 0.001, 0.01])\n",
    "    ax.set_xticklabels(['-4','-3','-2'])\n",
    "    ax.set_xlabel(r'$\\log_{10}$(MACE p-value)')\n",
    "    ax.set_ylim(-0.2,ymax)\n",
    "    ax.set_ylabel('maxPeak SNR')\n",
    "    ax.legend([h1,h2],[r'GEM SNR$\\geq$1',r'GEM SNR$<$1'], loc=1)\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "fig.savefig('../Figures/Comparison_scores_maxPeak_vs_MACE.png', bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = ['Fkh1 log','Fkh1 stat','Fkh2 log','Fkh2 stat']\n",
    "\n",
    "fig = plt.figure(figsize=(20,12))\n",
    "ax1 = plt.subplot2grid((100, 100), (0, 0), rowspan=44, colspan=45)\n",
    "ax2 = plt.subplot2grid((100, 100), (0, 55), rowspan=44, colspan=45)\n",
    "ax3 = plt.subplot2grid((100, 100), (56, 0), rowspan=44, colspan=45)\n",
    "ax4 = plt.subplot2grid((100, 100), (56, 55), rowspan=44, colspan=45)\n",
    "axes = [ax1,ax2,ax3,ax4]\n",
    "\n",
    "for k in range(len(experiments)):\n",
    "    ax = axes[k]\n",
    "    exp = experiments[k]\n",
    "    \n",
    "    df_targets = df[['maxPeak_AD_12 '+exp, 'GEM '+exp, 'MACE '+exp]]\n",
    "    df_targets['GEM '+exp] = df_targets['GEM '+exp].fillna(0)\n",
    "    \n",
    "    df_targets_mace = df_targets[df_targets['MACE '+exp] <= t[2]]\n",
    "    df_targets_mace_low = df_targets[(df_targets['MACE '+exp] > t[2]) & (df_targets['MACE '+exp] < 0.01)]\n",
    "    df_targets_notmace = df_targets[df_targets['MACE '+exp].isnull()]\n",
    "\n",
    "    x1 = df_targets_mace['GEM '+exp]\n",
    "    y1 = df_targets_mace['maxPeak_AD_12 '+exp]\n",
    "    \n",
    "    x2 = df_targets_mace_low['GEM '+exp]\n",
    "    y2 = df_targets_mace_low['maxPeak_AD_12 '+exp]\n",
    "    \n",
    "    x3 = df_targets_notmace['GEM '+exp]\n",
    "    y3 = df_targets_notmace['maxPeak_AD_12 '+exp]\n",
    "\n",
    "    h1 = ax.scatter(x1,y1,c=['blue']*len(x1),alpha=0.5)\n",
    "    h2 = ax.scatter(x2,y2,c=['green']*len(x3),alpha=0.5)\n",
    "    h3 = ax.scatter(x3,y3,c=['red']*len(x2),alpha=0.5)\n",
    "    \n",
    "\n",
    "    ax.plot(np.linspace(0,df_targets['GEM '+exp].dropna().max(),100), [t[0]]*100,'k-.')\n",
    "    ymax = 1.65*df_targets['maxPeak_AD_12 '+exp].max()\n",
    "    ax.plot([t[1]]*100, np.linspace(0,ymax,100),'k-.')\n",
    "    \n",
    "    ax.set_xlabel('GEM SNR')\n",
    "    ax.set_ylabel('maxPeak SNR')\n",
    "    # str(t[2])+r'$<$MACE < '+str(0.01)\n",
    "    ax.legend([h1,h2,h3],[r'MACE$\\leq$'+str(t[2]), r'MACE$\\in (0.005, 0.01)$',r'MACE$>$'+str(0.01)],loc=1)\n",
    "    ax.set_ylim(-0.2,ymax)\n",
    "    ax.set_xlim(-0.2,1.01*df_targets['GEM '+exp].dropna().max())\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "fig.savefig('../Figures/Comparison_scores_maxPeak_vs_GEM.png', bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = ['Fkh1 log','Fkh1 stat','Fkh2 log','Fkh2 stat']\n",
    "\n",
    "fig = plt.figure(figsize=(20,12))\n",
    "ax1 = plt.subplot2grid((100, 100), (0, 0), rowspan=44, colspan=45)\n",
    "ax2 = plt.subplot2grid((100, 100), (0, 55), rowspan=44, colspan=45)\n",
    "ax3 = plt.subplot2grid((100, 100), (56, 0), rowspan=44, colspan=45)\n",
    "ax4 = plt.subplot2grid((100, 100), (56, 55), rowspan=44, colspan=45)\n",
    "axes = [ax1,ax2,ax3,ax4]\n",
    "\n",
    "for k in range(len(experiments)):\n",
    "    ax = axes[k]\n",
    "    exp = experiments[k]\n",
    "    \n",
    "    df_targets = df[['maxPeak_AD_12 '+exp, 'GEM '+exp, 'MACE '+exp]]\n",
    "    df_targets['GEM '+exp] = df_targets['GEM '+exp].fillna(0)\n",
    "    \n",
    "    df_targets_max = df_targets[df_targets['maxPeak_AD_12 '+exp] >= t[0]]\n",
    "    df_targets_notmax = df_targets[df_targets['maxPeak_AD_12 '+exp] < t[0]]\n",
    "\n",
    "    x1 = df_targets_max['MACE '+exp]\n",
    "    y1 = df_targets_max['GEM '+exp]\n",
    "    \n",
    "    x2 = df_targets_notmax['MACE '+exp]\n",
    "    y2 = df_targets_notmax['GEM '+exp]\n",
    "\n",
    "    h1 = ax.scatter(x1,y1,c=['blue']*len(x1),alpha=0.5)\n",
    "    h2 = ax.scatter(x2,y2,c=['red']*len(x2),alpha=0.25)\n",
    "\n",
    "    ax.plot(np.linspace(0,0.01,100), [t[1]]*100,'k-.')\n",
    "    ymax = 1.03*df_targets['GEM '+exp].dropna().max()\n",
    "    ax.plot([t[2]]*100, np.linspace(0,ymax,100),'k-.')   \n",
    "    \n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlim(0.0001, 0.01)\n",
    "    ax.set_xticks([0.0001, 0.001, 0.01])\n",
    "    ax.set_xticklabels(['-4','-3','-2'])\n",
    "    ax.set_xlabel(r'$\\log_{10}$(MACE p-value)')\n",
    "    ax.set_ylim(-0.2,ymax)\n",
    "    ax.set_ylabel('GEM SNR')\n",
    "    ax.legend([h1,h2],[r'maxPeak SNR$\\geq$'+str(t[0]), r'maxPeak SNR$<$'+str(t[0])], loc=1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('../Figures/Comparison_scores_GEM_vs_MACE.png', bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlap in targets between the 3 peak detection methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "experiments = ['Fkh1 log','Fkh1 stat','Fkh2 log','Fkh2 stat']\n",
    "\n",
    "for i, exp in enumerate(experiments):\n",
    "    labels = venn.get_labels([df[df['GEM '+exp]>=t[1]].index.values,\n",
    "                              df[df['MACE '+exp]<=t[2]].index.values,\n",
    "                              df[df['maxPeak_AD_12 '+exp]>=t[0]].index.values], \n",
    "                              fill=['number']);\n",
    "\n",
    "    fig, ax = venn.venn3(labels, names=['GEM','MACE','maxPeak'], legend=True, ymax=1.2)\n",
    "    fig.savefig('../Figures/Venn_3_methods_'+exp+'.png', bbox_inches='tight', dpi=200)\n",
    "    plt.clf()\n",
    "    \n",
    "    fig, ax = venn.venn3(labels, names=['GEM','MACE','maxPeak'], legend=False, ymax=1)\n",
    "    fig.savefig('../Figures/Venn_3_methods_'+exp+'_NO_LEGEND.png', bbox_inches='tight', dpi=300)\n",
    "    plt.clf()\n",
    "    \n",
    "# show the output\n",
    "img1 = mpimg.imread('../Figures/Venn_3_methods_Fkh1 log_NO_LEGEND.png',)\n",
    "img2 = mpimg.imread('../Figures/Venn_3_methods_Fkh1 stat_NO_LEGEND.png')\n",
    "img3 = mpimg.imread('../Figures/Venn_3_methods_Fkh2 log_NO_LEGEND.png')\n",
    "img4 = mpimg.imread('../Figures/Venn_3_methods_Fkh2 stat_NO_LEGEND.png')\n",
    "\n",
    "plt.figure().set_size_inches(25,25)\n",
    "plt.subplot(221)\n",
    "plt.imshow(img1)\n",
    "plt.axis('off')\n",
    "plt.subplot(222)\n",
    "plt.imshow(img2)\n",
    "plt.axis('off')\n",
    "plt.subplot(223)\n",
    "plt.imshow(img3)\n",
    "plt.axis('off')\n",
    "plt.subplot(224)\n",
    "plt.imshow(img4)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define targets and save subdataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our targets: 2x PDM, 3x PDM and CCR\n",
    "\"Targets\" are predicted by 2 out of 3: maxPeak, GEM and Mace. Also save 3 out of 3 separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['maxPeak_AD_12','GEM','MACE']\n",
    "experiments = ['Fkh1 log','Fkh1 stat','Fkh2 log','Fkh2 stat']\n",
    "\n",
    "df_targets_list = []\n",
    "df_targets_ccr_list = []\n",
    "df_targets_3x_PDM_list = []\n",
    "\n",
    "####################\n",
    "# for each exp, loop over methods and keep only those shown by the method until we reach a 'common core'\n",
    "####################\n",
    "for exp in experiments:  \n",
    "    # 2x methods\n",
    "    df_targets = df[((df['maxPeak_AD_12 '+exp] >= t[0]) & (df['GEM '+exp] >= t[1])) \n",
    "                 | ((df['maxPeak_AD_12 '+exp] >= t[0]) & (df['MACE '+exp] <= t[2])) \n",
    "                 | ((df['GEM '+exp] >= t[1]) & (df['MACE '+exp] <= t[2]))]\n",
    "    df_targets.to_excel('../Tables/targets_'+exp+'.xlsx')\n",
    "       \n",
    "    # CCR\n",
    "    df_targets_ccr = df_targets[~df_targets['Expression peak phase'].isnull()]\n",
    "    \n",
    "    # 3x methods\n",
    "    df_targets_3x_PDM = df[(df['maxPeak_AD_12 '+exp] >= t[0]) & (df['GEM '+exp] >= t[1]) & (df['MACE '+exp] <= t[2])]\n",
    "        \n",
    "    # append all to lists\n",
    "    df_targets_list.append(df_targets)\n",
    "    df_targets_3x_PDM_list.append(df_targets_3x_PDM)\n",
    "    df_targets_ccr_list.append(df_targets_ccr)\n",
    "    \n",
    "    print(exp, '\\t\\t', len(df_targets), '('+str(len(df_targets_3x_PDM))+')', '\\t\\tCell cycle regulated:', len(df_targets_ccr),\n",
    "         '\\t\\t','Metabolic enzymes:', len(df_targets[df_targets['is enzyme']]))\n",
    "\n",
    "    \n",
    "print('Fkh1 unique targets in common core:', len(list(set(df_targets_list[0].index.tolist()+df_targets_list[1].index.tolist()))))\n",
    "print('Fkh2 unique targets in common core:', len(list(set(df_targets_list[2].index.tolist()+df_targets_list[3].index.tolist()))))\n",
    "\n",
    "\n",
    "######################\n",
    "# Export to Excel\n",
    "######################\n",
    "# start from empty 3x PDM file\n",
    "pdm_path = '../Tables/subset_targets_3x_PDM.xlsx'\n",
    "try:\n",
    "    os.remove(pdm_path)\n",
    "except: # fails if it doesn't exist\n",
    "    pass\n",
    "\n",
    "writer = pd.ExcelWriter(pdm_path, engine='xlsxwriter')\n",
    "for exp,subdf in zip(experiments,df_targets_3x_PDM_list):\n",
    "    subdf.to_excel(writer,sheet_name=exp)\n",
    "\n",
    "writer.save()\n",
    "\n",
    "# start from empty CCR file\n",
    "ccr_path = '../Tables/subset_targets_CCR.xlsx'\n",
    "try:\n",
    "    os.remove(ccr_path)\n",
    "except: # fails if it doesn't exist\n",
    "    pass\n",
    "\n",
    "writer = pd.ExcelWriter(ccr_path, engine='xlsxwriter')\n",
    "for exp,subdf in zip(experiments,df_targets_ccr_list):\n",
    "    subdf.to_excel(writer,sheet_name=exp)\n",
    "\n",
    "writer.save()\n",
    "\n",
    "######################\n",
    "# give readable names to the sub-dataframes\n",
    "######################\n",
    "# Targets shown by 2 methods\n",
    "df_Fkh1log_targets = df_targets_list[0]\n",
    "df_Fkh1stat_targets = df_targets_list[1]\n",
    "df_Fkh2log_targets = df_targets_list[2]\n",
    "df_Fkh2stat_targets = df_targets_list[3]\n",
    "\n",
    "# cell cycle dependent targets\n",
    "df_Fkh1log_targets_ccr = df_targets_ccr_list[0]\n",
    "df_Fkh1stat_targets_ccr = df_targets_ccr_list[1]\n",
    "df_Fkh2log_targets_ccr = df_targets_ccr_list[2]\n",
    "df_Fkh2stat_targets_ccr = df_targets_ccr_list[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Targets in common among MacIsaac, Venters & Ostrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Fkh1log_targets_literature = df[(df['MacIsaac 2006 Fkh1']) &\n",
    "                                   (df['Venters 2011 Fkh1']) &\n",
    "                                   (df['Ostrow 2014 Fkh1'])]\n",
    "\n",
    "df_Fkh2log_targets_literature = df[(df['MacIsaac 2006 Fkh2']) &\n",
    "                                   (df['Venters 2011 Fkh2']) &\n",
    "                                   (df['Ostrow 2014 Fkh2'])]\n",
    "\n",
    "######################\n",
    "# Export to Excel\n",
    "######################\n",
    "path = '../Tables/literature_targets_macIsaac_Venters_and_Ostrow.xlsx'\n",
    "try:\n",
    "    os.remove(path)\n",
    "except: # fails if it doesn't exist\n",
    "    pass\n",
    "\n",
    "writer = pd.ExcelWriter(path, engine='xlsxwriter')\n",
    "for fkh,subdf in zip(['Fkh1','Fkh2'],[df_Fkh1log_targets_literature,df_Fkh2log_targets_literature]):\n",
    "    subdf.to_excel(writer,sheet_name=fkh)\n",
    "\n",
    "writer.save()\n",
    "\n",
    "#### Print the gene names\n",
    "print('Common core among 3 literature ChIP studies for Fkh1 in log phase:', len(df_Fkh1log_targets_literature))\n",
    "print(df_Fkh1log_targets_literature['Standard name'].values)\n",
    "\n",
    "print('Common core among 3 literature ChIP studies for Fkh2 in log phase:', len(df_Fkh2log_targets_literature))\n",
    "print(df_Fkh2log_targets_literature['Standard name'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Targets in common among all 4 studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Fkh1log_targets_4x_ChIP = df_Fkh1log_targets[(df_Fkh1log_targets['MacIsaac 2006 Fkh1']) &\n",
    "                                                   (df_Fkh1log_targets['Venters 2011 Fkh1']) &\n",
    "                                                   (df_Fkh1log_targets['Ostrow 2014 Fkh1'])]\n",
    "\n",
    "df_Fkh2log_targets_4x_ChIP = df_Fkh2log_targets[(df_Fkh2log_targets['MacIsaac 2006 Fkh2']) &\n",
    "                                                   (df_Fkh2log_targets['Venters 2011 Fkh2']) &\n",
    "                                                   (df_Fkh2log_targets['Ostrow 2014 Fkh2'])]\n",
    "\n",
    "print('Common core among 4 ChIP studies for Fkh1 in log phase:', len(df_Fkh1log_targets_4x_ChIP))\n",
    "print(df_Fkh1log_targets_4x_ChIP['Standard name'].values)\n",
    "\n",
    "print('Enzymes', len(df_Fkh1log_targets_4x_ChIP[df_Fkh1log_targets_4x_ChIP['is enzyme']]))\n",
    "print(df_Fkh1log_targets_4x_ChIP[df_Fkh1log_targets_4x_ChIP['is enzyme']]['Standard name'].values)\n",
    "\n",
    "\n",
    "print('Common core among 4 ChIP studies for Fkh2 in log phase:', len(df_Fkh2log_targets_4x_ChIP))\n",
    "print(df_Fkh2log_targets_4x_ChIP['Standard name'].values)\n",
    "\n",
    "print('Enzymes', len(df_Fkh2log_targets_4x_ChIP[df_Fkh2log_targets_4x_ChIP['is enzyme']]))\n",
    "print(df_Fkh2log_targets_4x_ChIP[df_Fkh2log_targets_4x_ChIP['is enzyme']]['Standard name'].values)\n",
    "\n",
    "######################\n",
    "# Export to Excel\n",
    "######################\n",
    "path = '../Tables/subset_targets_4x_ChIP.xlsx'\n",
    "try:\n",
    "    os.remove(path)\n",
    "except: # fails if it doesn't exist\n",
    "    pass\n",
    "\n",
    "writer = pd.ExcelWriter(path, engine='xlsxwriter')\n",
    "for fkh,subdf in zip(['Fkh1','Fkh2'],[df_Fkh1log_targets_4x_ChIP,df_Fkh2log_targets_4x_ChIP]):\n",
    "    subdf.to_excel(writer,sheet_name=fkh)\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Novel targets\n",
    "Novel as in not shown to be targets by Venters et al. or Ostrow et al or MacIsaac et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_Fkh1log_targets['Suggested by (Fkh1)'] = ''\n",
    "df_Fkh1log_targets['Suggested by (Fkh1)'] = df_Fkh1log_targets.apply(lambda row: utils.identify_papers_showing_target(row, 'Fkh1 log'),axis=1)\n",
    "df_Fkh2log_targets['Suggested by (Fkh2)'] = ''\n",
    "df_Fkh2log_targets['Suggested by (Fkh2)'] = df_Fkh2log_targets.apply(lambda row: utils.identify_papers_showing_target(row, 'Fkh2 log'),axis=1)\n",
    "\n",
    "# Define variables for verified targets for later\n",
    "df_verified_targets_Fkh1 = df_Fkh1log_targets[df_Fkh1log_targets.apply(lambda x: len(x['Suggested by (Fkh1)'].split(\", \")) > 1, axis = 1)]\n",
    "df_verified_targets_Fkh2 = df_Fkh2log_targets[df_Fkh2log_targets.apply(lambda x: len(x['Suggested by (Fkh2)'].split(\", \")) > 1, axis = 1)]\n",
    "df_verified_3_targets_Fkh1 = df_Fkh1log_targets[df_Fkh1log_targets.apply(lambda x: len(x['Suggested by (Fkh1)'].split(\", \")) > 2, axis = 1)]\n",
    "df_verified_3_targets_Fkh2 = df_Fkh2log_targets[df_Fkh2log_targets.apply(lambda x: len(x['Suggested by (Fkh2)'].split(\", \")) > 2, axis = 1)]\n",
    "df_verified_4_targets_Fkh1 = df_Fkh1log_targets[df_Fkh1log_targets.apply(lambda x: len(x['Suggested by (Fkh1)'].split(\", \")) > 3, axis = 1)]\n",
    "df_verified_4_targets_Fkh2 = df_Fkh2log_targets[df_Fkh2log_targets.apply(lambda x: len(x['Suggested by (Fkh2)'].split(\", \")) > 3, axis = 1)]\n",
    "\n",
    "# novel targets\n",
    "df_novel_Fkh1 = df_Fkh1log_targets[df_Fkh1log_targets['Suggested by (Fkh1)'] == 'Mondeel']\n",
    "df_novel_Fkh2 = df_Fkh2log_targets[df_Fkh2log_targets['Suggested by (Fkh2)'] == 'Mondeel']\n",
    "\n",
    "print('Number of novel targets (Fkh1, Fkh2):', len(df_novel_Fkh1), len(df_novel_Fkh2))\n",
    "print('Number of enzymes among novel targets (Fkh1, Fkh2):', \n",
    "      len(df_novel_Fkh1[df_novel_Fkh1['is enzyme']]), \n",
    "      len(df_novel_Fkh2[df_novel_Fkh2['is enzyme']]))\n",
    "\n",
    "######################\n",
    "# Export to Excel\n",
    "######################\n",
    "# start from empty CCR file\n",
    "novel_path = '../Tables/subset_targets_novel.xlsx'\n",
    "try:\n",
    "    os.remove(novel_path)\n",
    "except: # fails if it doesn't exist\n",
    "    pass\n",
    "\n",
    "writer = pd.ExcelWriter(novel_path, engine='xlsxwriter')\n",
    "df_novel_Fkh1.to_excel(writer,sheet_name='Fkh1')\n",
    "df_novel_Fkh2.to_excel(writer,sheet_name='Fkh2')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target overview table for Pathview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_exo_score(row, exo_targets):\n",
    "    \n",
    "    if row.name in exo_targets:\n",
    "        score = 1\n",
    "    else:\n",
    "        score = np.NaN\n",
    "    \n",
    "    return score\n",
    "\n",
    "def assign_consensus_score(row, df, exo_targets):\n",
    "    \n",
    "    evidence_exo = row.name in exo_targets\n",
    "    evidence_chip = df.loc[row.name]['MacIsaac 2006 '+exp[:-4].rstrip()] or df.loc[row.name]['Venters 2011 '+exp[:-4].rstrip()] or df.loc[row.name]['Ostrow 2014 '+exp[:-4].rstrip()]\n",
    "    \n",
    "    if evidence_chip and evidence_exo:\n",
    "        score = 1\n",
    "    elif evidence_exo:\n",
    "        score = 0\n",
    "    elif evidence_chip:\n",
    "        score = -1\n",
    "    else:\n",
    "        score = np.NaN\n",
    "    \n",
    "    return score\n",
    "\n",
    "df_pathview = pd.DataFrame(df,copy=True)\n",
    "df_pathview = df_pathview[['Standard name','Description']]\n",
    "\n",
    "# For all genes get boolean for being target in each experiment\n",
    "for i,exp in enumerate(experiments):\n",
    "    df_pathview['Target '+exp] = df_pathview.apply(lambda row: assign_exo_score(row, df_targets_list[i].index), axis=1)\n",
    "        \n",
    "# Consensus only in log phase\n",
    "for i,exp in [(0,'Fkh1 log'),(2, 'Fkh2 log')]:\n",
    "    df_pathview['Consensus '+exp] = df_pathview.apply(lambda row: assign_consensus_score(row, df, df_targets_list[i].index), axis=1)\n",
    "        \n",
    "df_pathview.to_excel('../Tables/pathview_targets.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print list of target genes for each experiment\n",
    "highlight enzymes and novel targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i,df_targets in enumerate(df_targets_list):\n",
    "    exp = experiments[i]\n",
    "    print(exp)\n",
    "    \n",
    "    l = df_targets.index.values\n",
    "    l_std = [df_targets.loc[g]['Standard name'] for g in l]\n",
    "    l_std = sorted(l_std)\n",
    "    \n",
    "    for g in l_std:\n",
    "        print(g,end=', ')\n",
    "    print('\\n')\n",
    "    \n",
    "    print('Metabolic enzymes:', end='\\t')\n",
    "    for g in l:\n",
    "        if df_targets.loc[g]['is enzyme']:\n",
    "            print(df_targets.loc[g]['Standard name'],end=', ')\n",
    "    print('\\n')\n",
    "    \n",
    "    print('Novel targets:', end='\\t')\n",
    "    for g in l:\n",
    "        if (not df_targets.loc[g]['Venters 2011 ' + exp[:4]]) and (not df_targets.loc[g]['Ostrow 2014 ' + exp[:4]]) \\\n",
    "        and (not df_targets.loc[g]['MacIsaac 2006 ' + exp[:4]]):\n",
    "            print(df_targets.loc[g]['Standard name'],end=', ')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print 3x PDM targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_3x_pdm = []\n",
    "Fkh1_3x_pdm = []\n",
    "Fkh2_3x_pdm = []\n",
    "for i,exp in enumerate(experiments):\n",
    "    print(exp)\n",
    "    d = df_targets_3x_PDM_list[i]\n",
    "    \n",
    "    l = d['Standard name'].tolist()\n",
    "    \n",
    "    # save the genes\n",
    "    total_3x_pdm.extend(l)\n",
    "    if i < 2:\n",
    "        Fkh1_3x_pdm.extend(l)\n",
    "    else:\n",
    "        Fkh2_3x_pdm.extend(l)\n",
    "    \n",
    "    print(', '.join(l))\n",
    "    print('enzymes')\n",
    "    print(d[d['is enzyme']]['Standard name'].tolist())\n",
    "    print('novel')\n",
    "    if 'Fkh1' in exp:\n",
    "        novel_3x = [g for g in d['Standard name'].tolist() if g in df_novel_Fkh1['Standard name'].tolist()]\n",
    "    else:\n",
    "        novel_3x = [g for g in d['Standard name'].tolist() if g in df_novel_Fkh2['Standard name'].tolist()]\n",
    "    \n",
    "    print(novel_3x)\n",
    "    print()\n",
    "    \n",
    "# total unique gene counts\n",
    "total_3x_pdm = list(set(total_3x_pdm))\n",
    "Fkh1_3x_pdm = list(set(Fkh1_3x_pdm))\n",
    "Fkh2_3x_pdm = list(set(Fkh2_3x_pdm))\n",
    "\n",
    "print('Total number of unique 3x PDM verfied targets:',len(total_3x_pdm))\n",
    "print('Number of unique 3x PDM verfied targets for Fkh1:',len(Fkh1_3x_pdm))\n",
    "print('Number of unique 3x PDM verfied targets for Fkh2:',len(Fkh2_3x_pdm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [df_targets_list]\n",
    "data.append([df_Fkh1log_targets_4x_ChIP,np.NaN,df_Fkh2log_targets_4x_ChIP,np.NaN])\n",
    "data.append(df_targets_3x_PDM_list)\n",
    "data.append([df_novel_Fkh1, np.NaN, df_novel_Fkh2, np.NaN])\n",
    "data.append(df_targets_ccr_list)\n",
    "data.append([df_temp[df_temp['is enzyme']] for df_temp in df_targets_list])\n",
    "data.append([df_temp[df_temp['yeast7']] for df_temp in df_targets_list])\n",
    "\n",
    "data_counts = [[len(l[i]) if type(l[i])==pd.DataFrame else l[i] for l in data] for i in range(len(experiments)) ]\n",
    "\n",
    "\n",
    "df_counts = pd.DataFrame(data_counts, columns=[\"# Targets\",'# 4x ChIP verified','#3x PDM verified',\"# Novel targets\",'# CCR',\n",
    "                                               '# enzymes','# metabolic enzymes'], \n",
    "                         index=experiments).transpose()\n",
    "display(df_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Venn Diagrams of overlap with previous studies\n",
    "Here we plot a sequence of Venn diagrams of overlapping & unique targets between this study and previous studies:\n",
    "- Mondeel et al. (this study)\n",
    "- Ostrow et al. http://doi.org/10.1371/journal.pone.0087647\n",
    "- Venters et al. http://doi.org/10.1016/j.molcel.2011.01.015\n",
    "- MacIsaac et al. http://doi.org/10.1186/1471-2105-7-113## Compare common core with literature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MacIsaac, Venters & Ostrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = venn.get_labels([df[df['MacIsaac 2006 Fkh1']].index.values,\n",
    "                          df[df['Venters 2011 Fkh1']].index.values,\n",
    "                          df[df['Ostrow 2014 Fkh1']].index.values],\n",
    "                          fill=['number'])\n",
    "fig, ax = venn.venn3(labels, names=['MacIsaac et al.',\n",
    "                                    'Venters et al.',\n",
    "                                    'Ostrow et al.'], legend=True, ymax=1.2)\n",
    "fig.show()\n",
    "fig.savefig('../Figures/Overlap_targets_venters_ostrow_macIsaac_Fkh1log.jpg', bbox_inches='tight', dpi=200)\n",
    "plt.clf()\n",
    "\n",
    "print(labels['111'],\"Out of\",sum([int(k) for k in list(labels.values())]),\"Overlapping among all three studies.\")\n",
    "\n",
    "labels = venn.get_labels([df[df['MacIsaac 2006 Fkh2']].index.values,\n",
    "                          df[df['Venters 2011 Fkh2']].index.values,\n",
    "                          df[df['Ostrow 2014 Fkh2']].index.values], \n",
    "                        fill=['number'])\n",
    "fig, ax = venn.venn3(labels, names=['MacIsaac et al.',\n",
    "                                    'Venters et al.',\n",
    "                                    'Ostrow et al.'], legend=True, ymax=1.2)\n",
    "fig.show()\n",
    "fig.savefig('../Figures/Overlap_targets_venters_ostrow_macIsaac_Fkh2log.jpg', bbox_inches='tight', dpi=200)\n",
    "\n",
    "print(labels['111'],\"Out of\",sum([int(k) for k in list(labels.values())]),\"Overlapping among all three studies.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All 4 ChIP studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,df_targets in enumerate(df_targets_list):\n",
    "    exp = experiments[i]\n",
    "    print(\"\\n\"+exp)\n",
    "    \n",
    "    labels = venn.get_labels([df[df['MacIsaac 2006 ' + exp[:4]]].index.values,\n",
    "                              df[df['Venters 2011 ' + exp[:4]]].index.values,        \n",
    "                              df[df['Ostrow 2014 ' + exp[:4]]].index.values, \n",
    "                              df_targets.index.values],\n",
    "                             fill=['number'])\n",
    "    \n",
    "    fig, ax = venn.venn4(labels, names=['MacIsaac et al.',\n",
    "                                        'Venters et al.',\n",
    "                                        'Ostrow et al.',\n",
    "                                        'This study'], legend=True, textsize=25, )\n",
    "\n",
    "    fig.savefig('../Figures/Overlap_'+exp+'.png', bbox_inches='tight', dpi=200)\n",
    "    fig.show()\n",
    "    plt.clf()\n",
    "    \n",
    "    print(labels['1111'],\"Out of\",sum([int(k) for k in list(labels.values())]),\"Overlapping among all four studies.\")\n",
    "    print(labels['0001'],\"Out of\",sum([int(k) for k in list(labels.values())]),\"New in our study\")\n",
    "    print(sum([int(k) for k in list(labels.values())]) - \n",
    "               sum([int(v) for v in [labels['1000'],labels['0100'],labels['0010'],labels['0001']]]),\n",
    "          \"Out of\",sum([int(k) for k in list(labels.values())]),\"Shown by at least 2 studies.\")\n",
    "\n",
    "    \n",
    "# show the output \n",
    "img1 = mpimg.imread('../Figures/Overlap_Fkh1 log.png',)\n",
    "img2 = mpimg.imread('../Figures/Overlap_Fkh1 stat.png')\n",
    "img3 = mpimg.imread('../Figures/Overlap_Fkh2 log.png')\n",
    "img4 = mpimg.imread('../Figures/Overlap_Fkh2 stat.png')\n",
    "\n",
    "plt.figure().set_size_inches(25,25)\n",
    "plt.subplot(221)\n",
    "plt.imshow(img1)\n",
    "plt.axis('off')\n",
    "plt.subplot(222)\n",
    "plt.imshow(img2)\n",
    "plt.axis('off')\n",
    "plt.subplot(223)\n",
    "plt.imshow(img3)\n",
    "plt.axis('off') \n",
    "plt.subplot(224)\n",
    "plt.imshow(img4)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GO term enrichment\n",
    "## GEMMER primary GO term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df = {'all':df,\n",
    "           'Fkh1 log': df_Fkh1log_targets,\n",
    "           'Fkh1 stat': df_Fkh1stat_targets,\n",
    "           'Fkh2 log': df_Fkh2log_targets,\n",
    "           'Fkh2 stat': df_Fkh2stat_targets}\n",
    "utils.get_functional_enrichment_multi(dict_df,'Primary GO term').style.applymap(utils._color_red_or_green)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build complete common core dataframe\n",
    "All relevant columns, all genes suggested by each of the 4 experiments and a column indicating the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_abbr = ['F1L','F1S','F2L','F2S']\n",
    "\n",
    "idx = []\n",
    "idx_to_exp = {}\n",
    "for i,df_targets in enumerate(df_targets_list):\n",
    "    l = df_targets.index.tolist()\n",
    "    idx.extend(l)\n",
    "    \n",
    "    # keep track of which experiments identified each gene in the common core\n",
    "    for g in l:\n",
    "        if g not in idx_to_exp:\n",
    "            idx_to_exp[g] = [exp_abbr[i]]\n",
    "        else:\n",
    "            idx_to_exp[g].append(exp_abbr[i])\n",
    "\n",
    "idx = list(set(idx))\n",
    "df_cc = df.loc[idx]\n",
    "df_cc['Target of'] = pd.Series(idx_to_exp)\n",
    "print(\"Number of genes in the common core:\", len(df_cc))\n",
    "\n",
    "df_cc_ccr = df_cc[~df_cc['Expression peak phase'].isnull()]\n",
    "print(\"Number of genes in the common core that are cell cycle dependent:\", len(df_cc_ccr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Fkh1,2 stackplot\n",
    "Combine all common core genes for all four experiments that are cell cycle dependent. Plot them in bins according to their phase of peak expression (Rowicka et al.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', size=12)          # controls default text sizes\n",
    "\n",
    "experiment = ['maxPeak_AD_12 Fkh1 log']\n",
    "data = [df_cc_ccr]\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = plt.subplot2grid((100, 1), (0, 0), rowspan=40)\n",
    "axes = [ax1]\n",
    "\n",
    "for k in range(len(experiment)):\n",
    "    ax = axes[k]\n",
    "    d = data[k]\n",
    "    exp = experiment[k]\n",
    "    \n",
    "    ax = utils.draw_stackplot_cc(d, exp, ax, no_xlabel=False, pos_mult=(0.9,1.2))\n",
    "    \n",
    "fig.set_size_inches(12,35)\n",
    "plt.show()\n",
    "fig.savefig('../Figures/stackplot_combined_relative_SNR_vs_phase.png', bbox_inches='tight', dpi=200)\n",
    "\n",
    "plt.rc('font', size=MEDIUM_SIZE)          # controls default text sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separated stackplots per experiment\n",
    "### Logarithmic phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', size=13)          # controls default text sizes\n",
    "\n",
    "experiment = ['Fkh1 log', 'Fkh2 log'] \n",
    "data = [df_Fkh1log_targets_ccr, df_Fkh2log_targets_ccr]\n",
    "\n",
    "# fig, axes = plt.subplots(2,1)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = plt.subplot2grid((100, 1), (0, 0), rowspan=68)\n",
    "ax2 = plt.subplot2grid((100, 1), (70, 0), rowspan=30) # needs more space\n",
    "\n",
    "axes = [ax1, ax2]\n",
    "\n",
    "for k in range(len(experiment)):\n",
    "    ax = axes[k]\n",
    "    d = data[k]\n",
    "    exp = experiment[k]\n",
    "    \n",
    "    if k==0:\n",
    "        no_label = True\n",
    "    else:\n",
    "        no_label = False\n",
    "    \n",
    "    ax = utils.draw_stackplot(d, t, exp, ax, no_label, pos_mult=(1,0.9))\n",
    "\n",
    "# # panel labels\n",
    "# ax1.text(-0.07, 1, 'A', transform=ax1.transAxes,\n",
    "#       fontsize=20, fontweight='bold', va='top', ha='left')\n",
    "# ax1.text(-0.07, -0.15, 'B', transform=ax1.transAxes,\n",
    "#       fontsize=20, fontweight='bold', va='top', ha='left')\n",
    "    \n",
    "fig.set_size_inches(13,15)\n",
    "plt.show()\n",
    "fig.savefig('../Figures/stackplot_separated_relative_SNR_vs_phase_log.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "plt.rc('font', size=MEDIUM_SIZE)          # controls default text sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stationary phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', size=13)          # controls default text sizes\n",
    "\n",
    "experiment = ['Fkh1 stat', 'Fkh2 stat'] \n",
    "data = [df_Fkh1stat_targets_ccr, df_Fkh2stat_targets_ccr]\n",
    "\n",
    "# fig, axes = plt.subplots(2,1)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = plt.subplot2grid((100, 1), (0, 0), rowspan=68)\n",
    "ax2 = plt.subplot2grid((100, 1), (70, 0), rowspan=30) # needs more space\n",
    "\n",
    "axes = [ax1, ax2]\n",
    "\n",
    "for k in range(len(experiment)):\n",
    "    ax = axes[k]\n",
    "    d = data[k]\n",
    "    exp = experiment[k]\n",
    "    \n",
    "    if k==0:\n",
    "        no_label = True\n",
    "    else:\n",
    "        no_label = False\n",
    "    \n",
    "    ax = utils.draw_stackplot(d, t, exp, ax, no_label, pos_mult=(1,0.9))\n",
    "\n",
    "# # panel labels\n",
    "# ax1.text(-0.07, 1, 'A', transform=ax1.transAxes,\n",
    "#       fontsize=20, fontweight='bold', va='top', ha='left')\n",
    "# ax1.text(-0.07, -0.15, 'B', transform=ax1.transAxes,\n",
    "#       fontsize=20, fontweight='bold', va='top', ha='left')\n",
    "    \n",
    "fig.set_size_inches(13,20)\n",
    "plt.show()\n",
    "fig.savefig('../Figures/stackplot_separated_relative_SNR_vs_phase_stat.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "plt.rc('font', size=MEDIUM_SIZE)          # controls default text sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase distribution of cell cycle regulated targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rc('font', size=MEDIUM_SIZE-1) # the numbers in the pies\n",
    "plt.rc('xtick', labelsize=MEDIUM_SIZE-1) # fontsize of the pie labels\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE-1) # experiments\n",
    "\n",
    "df_ccr = df[df['Expression peak phase'].notnull() ]\n",
    "\n",
    "perc_genome_wide = df_ccr['Expression peak phase'].value_counts(dropna=False) / len(df_ccr) * 100\n",
    "perc_genome_wide = perc_genome_wide.reindex(['G1','G1(P)','G1/S','S','G2','G2/M','M','M/G1'])\n",
    "\n",
    "titles = ['Genome-wide', 'Fkh1 logarithmic', 'Fkh1 stationary', 'Fkh2 logarithmic', 'Fkh2 stationary']\n",
    "\n",
    "colors_dict = {np.nan:\"#F8F8FF\",\"G1(P)\":\"lightblue\", \n",
    "               \"G1/S\":\"pink\", \"S\":\"#ff4c4c\", \"G2\":\"orange\",\n",
    "               \"G2/M\":\"#ffe119\",\"M\":\"#d65bd6\",\"M/G1\":\"#2ca02c\", \"G1\":\"lightgrey\"}\n",
    "\n",
    "data = [perc_genome_wide]\n",
    "\n",
    "fig = plt.figure()\n",
    "# total size = 21x43\n",
    "# two rows (10) and 4 columns (10), all spacings equal to 1\n",
    "# the image in the first row is centered between the 2nd and 3rd column\n",
    "cspace = 1\n",
    "rspace = 2\n",
    "r = 10 # row height\n",
    "c = 10 # col width\n",
    "ax1 = plt.subplot2grid((2*r+rspace, 4*c+3*cspace), (0, 16), colspan=c, rowspan=r)\n",
    "ax2 = plt.subplot2grid((2*r+rspace, 4*c+3*cspace), (r+rspace, 0), colspan=c, rowspan=r)\n",
    "ax3 = plt.subplot2grid((2*r+rspace, 4*c+3*cspace), (r+rspace, 1*(c+cspace)), colspan=c, rowspan=r)\n",
    "ax4 = plt.subplot2grid((2*r+rspace, 4*c+3*cspace), (r+rspace, 2*(c+cspace)), colspan=c, rowspan=r)\n",
    "ax5 = plt.subplot2grid((2*r+rspace, 4*c+3*cspace), (r+rspace, 3*(c+cspace)), colspan=c, rowspan=r)\n",
    "axes = [ax1,ax2,ax3,ax4,ax5]\n",
    "fig.set_size_inches(4*(c+cspace)/2.,2*(r+rspace)/2.)\n",
    "\n",
    "startangles = [90, 90, 90, 90, 90] # G1 roughly at the top\n",
    "pctdistance = [0.75,0.75,0.75,0.75,0.75]\n",
    "\n",
    "df_data = []\n",
    "for k in range(len(axes)):\n",
    "    ax = axes[k]\n",
    "    \n",
    "    if k == 0:\n",
    "        d = perc_genome_wide\n",
    "    else:\n",
    "        df_targets = df_targets_list[k-1]\n",
    "        df_targets_ccr = df_targets[~df_targets['Expression peak phase'].isnull()]\n",
    "        d = df_targets_ccr['Expression peak phase'].value_counts(dropna=False) / len(df_targets_ccr) * 100\n",
    "        d = d.reindex(['G1','G1(P)','G1/S','S','G2','G2/M','M','M/G1'])\n",
    "        d2 = d.fillna(0) # new series to drop nan later\n",
    "        d = d.dropna()\n",
    "                \n",
    "        l_up = []; l_down = []; l_same = []\n",
    "        for phase in d2.index:\n",
    "            if (d2.loc[phase] / perc_genome_wide.loc[phase] > 1) :\n",
    "                l_up.append(phase)\n",
    "            elif (d2.loc[phase] / perc_genome_wide.loc[phase] < 1):\n",
    "                l_down.append(phase)\n",
    "            else:\n",
    "                l_same.append(phase)\n",
    "        str_up = ', '.join(l_up)\n",
    "        str_down = ', '.join(l_down)\n",
    "        str_same = ', '.join(l_same)\n",
    "        \n",
    "        df_data.append([\n",
    "            round(sum([d2[i] - perc_genome_wide[i] for i in [0,1,2]]),2),\n",
    "            round(sum([d2[i] - perc_genome_wide[i] for i in [3]]),2),\n",
    "            round(sum([d2[i] - perc_genome_wide[i] for i in [4,5,6,7]]),2),\n",
    "            str_up,\n",
    "            str_down,\n",
    "            str_same\n",
    "        ])\n",
    "        \n",
    "    x = d.index\n",
    "    y = d.values\n",
    "    \n",
    "    colors = [colors_dict[func] for func in x]\n",
    "        \n",
    "    ax.pie(y, labels=x, autopct='%1.1f%%', pctdistance=pctdistance[k], shadow=False, colors=colors,\n",
    "           startangle=startangles[k], counterclock=False)\n",
    "    ax.set_title(titles[k])\n",
    "\n",
    "plt.show()\n",
    "fig.savefig('../Figures/Piechart_ccr_targets.pdf', bbox_inches='tight', dpi=200)\n",
    "\n",
    "df_ccr_enrichment = pd.DataFrame(df_data,columns=['Early','Mid','Late','Up','Down','No change'],\n",
    "                                   index=experiments)\n",
    "display(df_ccr_enrichment)\n",
    "\n",
    "plt.rc('font', size=MEDIUM_SIZE)\n",
    "plt.rc('xtick', labelsize=MEDIUM_SIZE)\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KEGG Pathways\n",
    "## All pathways "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pathway_counts = {} # pathway : {count: n,'genes':[gene1,gene2]}\n",
    "for i,df_exp in enumerate(df_targets_list):\n",
    "    exp = experiments[i]\n",
    "\n",
    "    # filter out those genes with at least one KEGG pathway\n",
    "    df_kegg = df_exp[df_exp['KEGG pathway'].notnull()] \n",
    "    \n",
    "    for i in range(len(df_kegg)): # loop over targets that are in KEGG pathways\n",
    "        row = df_kegg.iloc[i]\n",
    "        \n",
    "        if row['Standard name'] != '':\n",
    "            gene = row['Standard name']\n",
    "        else:\n",
    "            gene = row['Systematic name']\n",
    "\n",
    "        list_of_pathways = row['KEGG pathway'].split(', ')\n",
    "        \n",
    "        if len(list_of_pathways) == 0:\n",
    "            print(gene)\n",
    "        \n",
    "        for pathway in list_of_pathways:\n",
    "            if pathway not in pathway_counts:\n",
    "                # init\n",
    "                pathway_counts[pathway] = {e:[] for e in experiments}\n",
    "\n",
    "            # add current gene to correct experiment\n",
    "            pathway_counts[pathway][exp].append(gene)\n",
    "                \n",
    "    \n",
    "df_pathway_counts = pd.DataFrame.from_dict(pathway_counts, orient=\"index\").sort_index() \n",
    "\n",
    "# turn lists of genes into strings\n",
    "for exp in experiments:\n",
    "    df_pathway_counts[exp] = df_pathway_counts[exp].apply(lambda x: ', '.join(x) if type(x)==list else '')\n",
    "    \n",
    "\n",
    "### EXCEL EXPORT\n",
    "filename = \"../Tables/KEGG_pathways.xlsx\"\n",
    "writer = pd.ExcelWriter(filename, engine='xlsxwriter')\n",
    "workbook = writer.book\n",
    "df_pathway_counts.to_excel(writer, sheet_name='All')\n",
    "\n",
    "# formatting\n",
    "format_null = workbook.add_format({'text_wrap': True,'align':'left','font_size':10})\n",
    "worksheet = writer.sheets['All']\n",
    "worksheet.set_column('A:M',40,format_null)\n",
    "\n",
    "writer.save()\n",
    "\n",
    "print(len(df_pathway_counts))\n",
    "df_pathway_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out interesting rows for the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = [# Shared high-enrichment pathways\n",
    "    'Cell cycle - yeast','Meiosis - yeast',\n",
    "    #signalling\n",
    "    'MAPK signaling pathway - yeast','Mitophagy - yeast',\n",
    "    # metabolism\n",
    "    'Glycolysis / Gluconeogenesis','Citrate cycle (TCA cycle)', 'Oxidative phosphorylation',\n",
    "    'Biosynthesis of amino acids','Ribosome biogenesis in eukaryotes','Ribosome','Proteasome',\n",
    "    # RNA\n",
    "    'RNA degradation','RNA transport'\n",
    "    ]\n",
    "df_pathway_counts_reduced = df_pathway_counts.loc[keep]\n",
    "\n",
    "### EXCEL EXPORT\n",
    "filename = \"../Tables/KEGG_pathways_reduced.xlsx\"\n",
    "writer = pd.ExcelWriter(filename, engine='xlsxwriter')\n",
    "workbook = writer.book\n",
    "df_pathway_counts_reduced.to_excel(writer, sheet_name='All')\n",
    "\n",
    "# formatting\n",
    "format_null = workbook.add_format({'text_wrap': True,'align':'left','font_size':10})\n",
    "worksheet = writer.sheets['All']\n",
    "worksheet.set_column('A:M',40,format_null)\n",
    "\n",
    "writer.save()\n",
    "\n",
    "print(len(df_pathway_counts_reduced))\n",
    "df_pathway_counts_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List enzymes and novel targets among filtered kegg pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [x for y in df_pathway_counts_reduced.values.tolist() for x in y] # string for each cell\n",
    "l = [x.split(', ') for x in l]\n",
    "l = [x for y in l for x in y]\n",
    "l = list(set(l))\n",
    "l.remove('')\n",
    "\n",
    "# sub dataframe with all the listed targets\n",
    "# make sure to keep systematic name as a column\n",
    "# set index as standard name\n",
    "subdf = df.copy()\n",
    "subdf['Systematic name'] = df.index.tolist()\n",
    "subdf = subdf.set_index('Standard name').loc[l]\n",
    "\n",
    "# enzymes\n",
    "print('Enzymes:')\n",
    "print(subdf[subdf['is enzyme']].index.tolist())\n",
    "print()\n",
    "\n",
    "# novel\n",
    "print('Novel Fkh1:')\n",
    "print([x for x in subdf.index.tolist() if subdf.loc[x]['Systematic name'] in df_novel_Fkh1.index])\n",
    "print('Novel Fkh2:')\n",
    "print([x for x in subdf.index.tolist() if subdf.loc[x]['Systematic name'] in df_novel_Fkh2.index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All pathways for CCR targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathway_counts = {} # pathway : {count: n,'genes':[gene1,gene2]}\n",
    "for i,df_exp in enumerate(df_targets_list):\n",
    "    exp = experiments[i]\n",
    "\n",
    "    # filter out those genes with at least one KEGG pathway\n",
    "    df_kegg = df_exp[df_exp['KEGG pathway'].notnull()] \n",
    "    df_kegg_ccr = df_kegg[~df_kegg['Expression peak phase'].isnull()]\n",
    "    \n",
    "    for i in range(len(df_kegg_ccr)): # loop over targets that are in KEGG pathways\n",
    "        row = df_kegg_ccr.iloc[i]\n",
    "        \n",
    "        if row['Standard name'] != '':\n",
    "            gene = row['Standard name']\n",
    "        else:\n",
    "            gene = row['Systematic name']\n",
    "\n",
    "        list_of_pathways = row['KEGG pathway'].split(', ')\n",
    "        \n",
    "        if len(list_of_pathways) == 0:\n",
    "            print(gene)\n",
    "        \n",
    "        for pathway in list_of_pathways:\n",
    "            if pathway not in pathway_counts:\n",
    "                # init\n",
    "                pathway_counts[pathway] = {e:[] for e in experiments}\n",
    "\n",
    "            # add current gene to correct experiment\n",
    "            pathway_counts[pathway][exp].append(gene)\n",
    "                \n",
    "    \n",
    "df_pathway_counts = pd.DataFrame.from_dict(pathway_counts, orient=\"index\").sort_index() \n",
    "\n",
    "# turn lists of genes into strings\n",
    "for exp in experiments:\n",
    "    df_pathway_counts[exp] = df_pathway_counts[exp].apply(lambda x: ', '.join(x) if type(x)==list else '')\n",
    "    \n",
    "\n",
    "### EXCEL EXPORT\n",
    "filename = \"../Tables/KEGG_pathways_CCR.xlsx\"\n",
    "writer = pd.ExcelWriter(filename, engine='xlsxwriter')\n",
    "workbook = writer.book\n",
    "df_pathway_counts.to_excel(writer, sheet_name='All')\n",
    "\n",
    "# formatting\n",
    "format_null = workbook.add_format({'text_wrap': True,'align':'left','font_size':10})\n",
    "worksheet = writer.sheets['All']\n",
    "worksheet.set_column('A:M',40,format_null)\n",
    "\n",
    "writer.save()\n",
    "\n",
    "print(len(df_pathway_counts))\n",
    "df_pathway_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All pathways 4x verified targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathway_counts = {} # pathway : {count: n,'genes':[gene1,gene2]}\n",
    "for i,df_exp in [(0,df_Fkh1log_targets_4x_ChIP),(2,df_Fkh2log_targets_4x_ChIP)]:\n",
    "    exp = experiments[i]\n",
    "\n",
    "    # filter out those genes with at least one KEGG pathway\n",
    "    df_kegg = df_exp[df_exp['KEGG pathway'].notnull()] \n",
    "    \n",
    "    for i in range(len(df_kegg)): # loop over targets that are in KEGG pathways\n",
    "        row = df_kegg.iloc[i]\n",
    "        \n",
    "        if row['Standard name'] != '':\n",
    "            gene = row['Standard name']\n",
    "        else:\n",
    "            gene = row['Systematic name']\n",
    "\n",
    "        list_of_pathways = row['KEGG pathway'].split(', ')\n",
    "        \n",
    "        if len(list_of_pathways) == 0:\n",
    "            print(gene)\n",
    "        \n",
    "        for pathway in list_of_pathways:\n",
    "            if pathway not in pathway_counts:\n",
    "                # init\n",
    "                pathway_counts[pathway] = {e:[] for e in experiments}\n",
    "\n",
    "            # add current gene to correct experiment\n",
    "            pathway_counts[pathway][exp].append(gene)\n",
    "                \n",
    "    \n",
    "df_pathway_counts = pd.DataFrame.from_dict(pathway_counts, orient=\"index\").sort_index() \n",
    "\n",
    "# turn lists of genes into strings\n",
    "for exp in experiments:\n",
    "    df_pathway_counts[exp] = df_pathway_counts[exp].apply(lambda x: ', '.join(x) if type(x)==list else '')\n",
    "    \n",
    "\n",
    "### EXCEL EXPORT\n",
    "filename = \"../Tables/KEGG_pathways_4x.xlsx\"\n",
    "writer = pd.ExcelWriter(filename, engine='xlsxwriter')\n",
    "workbook = writer.book\n",
    "df_pathway_counts.to_excel(writer, sheet_name='All')\n",
    "\n",
    "# formatting\n",
    "format_null = workbook.add_format({'text_wrap': True,'align':'left','font_size':10})\n",
    "worksheet = writer.sheets['All']\n",
    "worksheet.set_column('A:M',40,format_null)\n",
    "\n",
    "writer.save()\n",
    "\n",
    "print(len(df_pathway_counts))\n",
    "df_pathway_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SI table: enzymes, expression phases, KEGG pathways and SGD description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_exp_enzymes = {}\n",
    "\n",
    "for i, df_exp in enumerate([df_Fkh1log_targets, df_Fkh1stat_targets, df_Fkh2log_targets, df_Fkh2stat_targets]):\n",
    "    exp = experiments[i]\n",
    "    \n",
    "    # filter out enzymes\n",
    "    df_exp = df_exp[df_exp['is enzyme']]\n",
    "    \n",
    "    # filter out columns\n",
    "    df_exp = df_exp[['Standard name','Expression peak time','Expression peak phase','Description','Name description','KEGG pathway','Primary GO term','Secondary GO term']]\n",
    "    \n",
    "    df_exp = df_exp.sort_values(by='Expression peak time')\n",
    "       \n",
    "    df_per_exp_enzymes[exp] = df_exp\n",
    "\n",
    "\n",
    "filename = \"../Tables/subset_targets_enzymes.xlsx\"\n",
    "\n",
    "writer = pd.ExcelWriter(filename, engine='xlsxwriter')\n",
    "workbook = writer.book\n",
    "\n",
    "for exp in experiments:\n",
    "    df_per_exp_enzymes[exp].to_excel(writer, sheet_name=exp)\n",
    "\n",
    "\n",
    "# formatting\n",
    "format_null = workbook.add_format({'text_wrap': True,'align':'left','font_size':10})\n",
    "\n",
    "for exp in experiments:\n",
    "    worksheet = writer.sheets[exp]\n",
    "    worksheet.set_column('A:D',20,format_null)\n",
    "    worksheet.set_column('E:E',100,format_null)\n",
    "    worksheet.set_column('F:G',40,format_null)\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target overlap between Fkh1 and Fkh2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_fkh1log = df_Fkh1log_targets.index\n",
    "idx_fkh1stat = df_Fkh1stat_targets.index\n",
    "idx_fkh2log = df_Fkh2log_targets.index\n",
    "idx_fkh2stat = df_Fkh2stat_targets.index\n",
    "\n",
    "idx_fkh1log_verified = df_verified_targets_Fkh1.index\n",
    "idx_fkh2log_verified = df_verified_targets_Fkh2.index\n",
    "\n",
    "idx_fkh1log_3_verified = df_verified_3_targets_Fkh1.index\n",
    "idx_fkh2log_3_verified = df_verified_3_targets_Fkh2.index\n",
    "\n",
    "idx_fkh1log_4_verified = df_verified_4_targets_Fkh1.index\n",
    "idx_fkh2log_4_verified = df_verified_4_targets_Fkh2.index\n",
    "\n",
    "# intersection\n",
    "idx_intersection_log = idx_fkh1log.intersection(idx_fkh2log)\n",
    "idx_intersection_stat = idx_fkh1stat.intersection(idx_fkh2stat)\n",
    "\n",
    "idx_intersection_log_verified = idx_fkh1log_verified.intersection(idx_fkh2log_verified)\n",
    "\n",
    "idx_intersection_log_3_verified = idx_fkh1log_3_verified.intersection(idx_fkh2log_3_verified)\n",
    "\n",
    "idx_intersection_log_4_verified = idx_fkh1log_4_verified.intersection(idx_fkh2log_4_verified)\n",
    "\n",
    "# fkh1 unique\n",
    "idx_unique_fkh1_log = idx_fkh1log.difference(idx_fkh2log)\n",
    "idx_unique_fkh1_stat = idx_fkh1stat.difference(idx_fkh2stat)\n",
    "\n",
    "idx_unique_fkh1_log_verified = idx_fkh1log_verified.difference(idx_fkh2log_verified)\n",
    "\n",
    "idx_unique_fkh1_log_3_verified = idx_fkh1log_3_verified.difference(idx_fkh2log_3_verified)\n",
    "\n",
    "idx_unique_fkh1_log_4_verified = idx_fkh1log_4_verified.difference(idx_fkh2log_4_verified)\n",
    "\n",
    "# fkh2 unique\n",
    "idx_unique_fkh2_log = idx_fkh2log.difference(idx_fkh1log)\n",
    "idx_unique_fkh2_stat = idx_fkh2stat.difference(idx_fkh1stat)\n",
    "\n",
    "idx_unique_fkh2_log_verified = idx_fkh2log_verified.difference(idx_fkh1log_verified)\n",
    "\n",
    "idx_unique_fkh2_log_3_verified = idx_fkh2log_3_verified.difference(idx_fkh1log_3_verified)\n",
    "\n",
    "idx_unique_fkh2_log_4_verified = idx_fkh2log_4_verified.difference(idx_fkh1log_4_verified)\n",
    "\n",
    "data = [[len(idx_intersection_log),len(idx_intersection_stat), len(idx_intersection_log_verified), len(idx_intersection_log_3_verified), len(idx_intersection_log_4_verified)],\n",
    "        [len(idx_unique_fkh1_log),len(idx_unique_fkh1_stat), len(idx_unique_fkh1_log_verified), len(idx_unique_fkh1_log_3_verified), len(idx_unique_fkh1_log_4_verified)],\n",
    "        [len(idx_unique_fkh2_log),len(idx_unique_fkh2_stat),len(idx_unique_fkh2_log_verified), len(idx_unique_fkh2_log_3_verified), len(idx_unique_fkh2_log_4_verified)]]\n",
    "\n",
    "df_overlap = pd.DataFrame(data, index=[\"Common targets\",\"Unique targets Fkh1\",\"Unique targets Fkh2\"], \n",
    "             columns=[\"Logarithmic\", \"Stationary\",\n",
    "                     \"2x ChIP verified\",\"3x ChIP verified\",\"4x ChIP verified\"])\n",
    "display(df_overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlap in ChIP-chip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_overlap = pd.DataFrame()\n",
    "\n",
    "lit_overlap.at['Common targets','MacIsaac'] = len(df[df['MacIsaac 2006 Fkh1'] & df['MacIsaac 2006 Fkh2']])\n",
    "lit_overlap.at['Unique targets Fkh1','MacIsaac'] = len(df[df['MacIsaac 2006 Fkh1'] & ~df['MacIsaac 2006 Fkh2']])\n",
    "lit_overlap.at['Unique targets Fkh2','MacIsaac'] = len(df[df['MacIsaac 2006 Fkh2'] & ~df['MacIsaac 2006 Fkh1']])\n",
    "\n",
    "lit_overlap.at['Common targets','Venters'] = len(df[df['Venters 2011 Fkh1'] & df['Venters 2011 Fkh2']])\n",
    "lit_overlap.at['Unique targets Fkh1','Venters'] = len(df[df['Venters 2011 Fkh1'] & ~df['Venters 2011 Fkh2']])\n",
    "lit_overlap.at['Unique targets Fkh2','Venters'] = len(df[df['Venters 2011 Fkh2'] & ~df['Venters 2011 Fkh1']])\n",
    "\n",
    "lit_overlap.at['Common targets','Ostrow'] = len(df[df['Ostrow 2014 Fkh1'] & df['Ostrow 2014 Fkh2']])\n",
    "lit_overlap.at['Unique targets Fkh1','Ostrow'] = len(df[df['Ostrow 2014 Fkh1'] & ~df['Ostrow 2014 Fkh2']])\n",
    "lit_overlap.at['Unique targets Fkh2','Ostrow'] = len(df[df['Ostrow 2014 Fkh2'] & ~df['Ostrow 2014 Fkh1']])\n",
    "\n",
    "lit_overlap = lit_overlap.astype(int)\n",
    "lit_overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How low is the signal for unique targets in the other Fkh?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame()\n",
    "\n",
    "# Fkh1 log uniques\n",
    "subdf = df.loc[idx_unique_fkh1_log]\n",
    "df_result.at['Fkh1 log', 'MaxPeak > 1'] = len(subdf[subdf['maxPeak_AD_12 Fkh2 log'] > 1])\n",
    "df_result.at['Fkh1 log', 'GEM > 1'] = len(subdf[subdf['GEM Fkh2 log'] > 1])\n",
    "df_result.at['Fkh1 log', 'MaxPeak < 0.005'] = len(subdf[subdf['MACE Fkh2 log'] < 0.005])\n",
    "print(len(subdf[(subdf['maxPeak_AD_12 Fkh2 log'] > 1) | (subdf['GEM Fkh2 log'] > 1) | \n",
    "                (subdf['MACE Fkh2 log'] < 0.005)]))\n",
    "\n",
    "# Fkh2 log uniques\n",
    "subdf = df.loc[idx_unique_fkh2_log]\n",
    "df_result.at['Fkh2 log', 'MaxPeak > 1'] = len(subdf[subdf['maxPeak_AD_12 Fkh1 log'] > 1])\n",
    "df_result.at['Fkh2 log', 'GEM > 1'] = len(subdf[subdf['GEM Fkh1 log'] > 1])\n",
    "df_result.at['Fkh2 log', 'MaxPeak < 0.005'] = len(subdf[subdf['MACE Fkh1 log'] < 0.005])\n",
    "print(len(subdf[(subdf['maxPeak_AD_12 Fkh1 log'] > 1) | (subdf['GEM Fkh1 log'] > 1) | \n",
    "                (subdf['MACE Fkh1 log'] < 0.005)]))\n",
    "\n",
    "# Fkh1 stat uniques\n",
    "subdf = df.loc[idx_unique_fkh1_stat]\n",
    "df_result.at['Fkh1 stat', 'MaxPeak > 1'] = len(subdf[subdf['maxPeak_AD_12 Fkh2 stat'] > 1])\n",
    "df_result.at['Fkh1 stat', 'GEM > 1'] = len(subdf[subdf['GEM Fkh2 stat'] > 1])\n",
    "df_result.at['Fkh1 stat', 'MaxPeak < 0.005'] = len(subdf[subdf['MACE Fkh2 stat'] < 0.005])\n",
    "print(len(subdf[(subdf['maxPeak_AD_12 Fkh2 stat'] > 1) | (subdf['GEM Fkh2 stat'] > 1) | \n",
    "                (subdf['MACE Fkh2 stat'] < 0.005)]))\n",
    "\n",
    "# Fkh2 stat uniques\n",
    "subdf = df.loc[idx_unique_fkh2_stat]\n",
    "df_result.at['Fkh2 stat', 'MaxPeak > 1'] = len(subdf[subdf['maxPeak_AD_12 Fkh1 stat'] > 1])\n",
    "df_result.at['Fkh2 stat', 'GEM > 1'] = len(subdf[subdf['GEM Fkh1 stat'] > 1])\n",
    "df_result.at['Fkh2 stat', 'MaxPeak < 0.005'] = len(subdf[subdf['MACE Fkh1 stat'] < 0.005])\n",
    "print(len(subdf[(subdf['maxPeak_AD_12 Fkh1 stat'] > 1) | (subdf['GEM Fkh1 stat'] > 1) | \n",
    "                (subdf['MACE Fkh1 stat'] < 0.005)]))\n",
    "\n",
    "pd.DataFrame(df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "data.append(df.loc[idx_unique_fkh1_log]['maxPeak_AD_12 Fkh2 log'])\n",
    "data.append(df.loc[idx_unique_fkh2_log]['maxPeak_AD_12 Fkh1 log'])\n",
    "data.append(df.loc[idx_unique_fkh1_stat]['maxPeak_AD_12 Fkh2 stat'])\n",
    "data.append(df.loc[idx_unique_fkh2_stat]['maxPeak_AD_12 Fkh1 stat'])\n",
    "            \n",
    "fig = plt.figure()\n",
    "res = plt.boxplot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing targets from the literature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_targets_fkh1 = df[(df['MacIsaac 2006 Fkh1']) | (df['Venters 2011 Fkh1']) | (df['Ostrow 2014 Fkh1'])]\n",
    "lit_targets_fkh2 = df[(df['MacIsaac 2006 Fkh2']) | (df['Venters 2011 Fkh2']) | (df['Ostrow 2014 Fkh2'])]\n",
    "\n",
    "print('Literature targets:',len(lit_targets_fkh1), len(lit_targets_fkh2))\n",
    "\n",
    "lit_targets_fkh1_missing = lit_targets_fkh1.loc[[idx for idx in lit_targets_fkh1.index if idx not in df_targets_list[0].index]]\n",
    "lit_targets_fkh2_missing = lit_targets_fkh2.loc[[idx for idx in lit_targets_fkh2.index if idx not in df_targets_list[2].index]]\n",
    "\n",
    "print('Missing literature targets:',len(lit_targets_fkh1_missing), len(lit_targets_fkh2_missing))\n",
    "\n",
    "lit_fkh1_missing_1method = lit_targets_fkh1_missing[(lit_targets_fkh1_missing['maxPeak_AD_12 Fkh1 log']>=t[0]) |\n",
    "                                                   (lit_targets_fkh1_missing['GEM Fkh1 log']>=t[1]) |\n",
    "                                                   (lit_targets_fkh1_missing['MACE Fkh1 log']<=t[2])]\n",
    "lit_fkh2_missing_1method = lit_targets_fkh2_missing[(lit_targets_fkh2_missing['maxPeak_AD_12 Fkh2 log']>=t[0]) |\n",
    "                                                   (lit_targets_fkh2_missing['GEM Fkh2 log']>=t[1]) |\n",
    "                                                   (lit_targets_fkh2_missing['MACE Fkh2 log']<=t[2])]\n",
    "\n",
    "print('Significant in one method:',len(lit_fkh1_missing_1method), len(lit_fkh2_missing_1method))\n",
    "\n",
    "\n",
    "lit_fkh1_missing_1method_low = lit_targets_fkh1_missing[(lit_targets_fkh1_missing['maxPeak_AD_12 Fkh1 log']>0) |\n",
    "                                                   (lit_targets_fkh1_missing['GEM Fkh1 log']>0) |\n",
    "                                                   (lit_targets_fkh1_missing['MACE Fkh1 log']<=0.01)]\n",
    "lit_fkh2_missing_1method_low = lit_targets_fkh2_missing[(lit_targets_fkh2_missing['maxPeak_AD_12 Fkh2 log']>0) |\n",
    "                                                   (lit_targets_fkh2_missing['GEM Fkh2 log']>0) |\n",
    "                                                   (lit_targets_fkh2_missing['MACE Fkh2 log']<=0.01)]\n",
    "\n",
    "print('Shows signal:',len(lit_fkh1_missing_1method_low), len(lit_fkh2_missing_1method_low))\n",
    "\n",
    "\n",
    "lit_fkh1_missing_insig = lit_targets_fkh1_missing[(lit_targets_fkh1_missing['maxPeak_AD_12 Fkh1 log']==0) &\n",
    "                                                   (lit_targets_fkh1_missing['GEM Fkh1 log'].isnull()) &\n",
    "                                                   (lit_targets_fkh1_missing['MACE Fkh1 log'].isnull())]\n",
    "lit_fkh2_missing_insig = lit_targets_fkh2_missing[(lit_targets_fkh2_missing['maxPeak_AD_12 Fkh2 log']==0) &\n",
    "                                                   (lit_targets_fkh2_missing['GEM Fkh2 log'].isnull()) &\n",
    "                                                   (lit_targets_fkh2_missing['MACE Fkh2 log'].isnull())]\n",
    "\n",
    "print('No signal:',len(lit_fkh1_missing_insig), len(lit_fkh2_missing_insig))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clb2 cluster genes as targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clb2_cluster = [\n",
    "    # Zhu et al. still oscillating in double deletion\n",
    "    'APC1','BUD8','CDC20','CHS2','NUM1','TEM1',\n",
    "    'YCL063W','YIL051W','YKL130C','YLR057W','YLR084C','YPR156C',\n",
    "    'YML119W','YMR032W',\n",
    "    # No more oscillations in the double deletion\n",
    "    'ACE2', 'ALK1', 'BUD3', 'BUD4', 'CDC5', 'CLB1', 'CLB2', 'HST3', 'KIP2', 'IQG1', 'MOB1', 'MYO1', 'SWI5', \n",
    "    'YIL158W', 'YLR190W', 'YML034W', 'YNL058C', 'YPL141C'\n",
    "    # deleted ORFs\n",
    "    # YCL013W\n",
    "    # changed annotations\n",
    "    # used to be: YCL012W: 'YCL014W' = BUD3, YCL062W: YCL063W, 'YML033W':YML034W\n",
    "    ]\n",
    "\n",
    "clb2_cluster_affected = ['ACE2', 'ALK1', 'BUD3', 'BUD4', 'CDC5', 'CLB1', 'CLB2', 'HST3', 'KIP2', 'IQG1', 'MOB1', 'MYO1', 'SWI5', \n",
    "    'YIL158W', 'YLR190W', 'YML034W', 'YNL058C', 'YPL141C']\n",
    "\n",
    "print('Num. genes in Clb2 cluster:',len(clb2_cluster))\n",
    "df_clb2cluster = df[df['Standard name'].isin(clb2_cluster)]\n",
    "\n",
    "\n",
    "recovered_targets = []\n",
    "\n",
    "for i in [0,2]:\n",
    "    \n",
    "    df_temp = df_targets_list[i]\n",
    "    \n",
    "    recovered_targets.extend(df_temp[df_temp['Standard name'].isin(clb2_cluster)]['Standard name'].tolist())\n",
    "    recovered_targets = list(set(recovered_targets))\n",
    "    \n",
    "print('2x recovered clb2 cluster genes:',len(recovered_targets))\n",
    "print(sorted(recovered_targets))\n",
    "recovered_targets_affected = [x for x in recovered_targets if x in clb2_cluster_affected]\n",
    "print('2x recovered clb2 cluster affected genes:',len(recovered_targets_affected))\n",
    "print(sorted(recovered_targets_affected))\n",
    "\n",
    "recovered_targets_ostrow = list(set(df_clb2cluster[df_clb2cluster['Ostrow 2014 Fkh1']]['Standard name'].tolist()\n",
    "               +df_clb2cluster[df_clb2cluster['Ostrow 2014 Fkh2']]['Standard name'].tolist()))\n",
    "print('Ostrow Clb2 cluster genes:', len(recovered_targets_ostrow))\n",
    "recovered_targets_affected_ostrow = [x for x in recovered_targets_ostrow if x in clb2_cluster_affected]\n",
    "print('Ostrow Clb2 cluster affected genes:', len(recovered_targets_affected_ostrow))\n",
    "\n",
    "recovered_targets_venters = list(set(df_clb2cluster[df_clb2cluster['Venters 2011 Fkh1']]['Standard name'].tolist()\n",
    "               +df_clb2cluster[df_clb2cluster['Venters 2011 Fkh2']]['Standard name'].tolist()))\n",
    "print('Venters Clb2 cluster genes:', len(recovered_targets_venters))\n",
    "recovered_targets_affected_venters = [x for x in recovered_targets_venters if x in clb2_cluster_affected]\n",
    "print('Venters Clb2 cluster affected genes:', len(recovered_targets_affected_venters))\n",
    "\n",
    "recovered_targets_macIsaac = list(set(df_clb2cluster[df_clb2cluster['MacIsaac 2006 Fkh1']]['Standard name'].tolist()\n",
    "               +df_clb2cluster[df_clb2cluster['MacIsaac 2006 Fkh2']]['Standard name'].tolist()))\n",
    "print('MacIsaac Clb2 cluster genes:', len(recovered_targets_macIsaac))\n",
    "recovered_targets_affected_macIsaac = [x for x in recovered_targets_macIsaac if x in clb2_cluster_affected]\n",
    "print('MacIsaac Clb2 cluster affected genes:', len(recovered_targets_affected_macIsaac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[df['Standard name'].isin(clb2_cluster)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data to generate CC regulation image\n",
    "Which methods in which phases showed which genes of the core regulatory network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = ['Fkh1 log','Fkh1 stat','Fkh2 log','Fkh2 stat']\n",
    "\n",
    "CC_genes = ['SWI4','SWI6','MBP1','SWI5','ACE2','FKH2','NDD1','MCM1', # TF's\n",
    "            'CLN3','CLN2','CLN1','CLB6','CLB5','CLB4','CLB3','CLB2','CLB1', # cyclins\n",
    "            'SIC1'] # other\n",
    "\n",
    "CC_genes_d = {g:{'MacIsaac':[],'Venters':[],'Ostrow':[],'This study':[]} for g in CC_genes}\n",
    "\n",
    "# gather the results\n",
    "for i,exp in enumerate(experiments):\n",
    "    for g in CC_genes:\n",
    "        if g in df_targets_list[i]['Standard name'].values.tolist():\n",
    "            CC_genes_d[g]['This study'].append(exp)\n",
    "    \n",
    "# check the literature if each gene was shown before\n",
    "macIsaac_Fkh1 = df[df['MacIsaac 2006 Fkh1']]['Standard name'].values.tolist()\n",
    "venters_Fkh1 = df[df['Venters 2011 Fkh1']]['Standard name'].values.tolist()\n",
    "ostrow_Fkh1 = df[df['Ostrow 2014 Fkh1']]['Standard name'].values.tolist()  \n",
    "macIsaac_Fkh2 = df[df['MacIsaac 2006 Fkh2']]['Standard name'].values.tolist()\n",
    "venters_Fkh2 = df[df['Venters 2011 Fkh2']]['Standard name'].values.tolist()\n",
    "ostrow_Fkh2 = df[df['Ostrow 2014 Fkh2']]['Standard name'].values.tolist()   \n",
    "\n",
    "for g in CC_genes:\n",
    "    if g in macIsaac_Fkh1:\n",
    "        CC_genes_d[g]['MacIsaac'].append('Fkh1')\n",
    "    if g in venters_Fkh1:\n",
    "        CC_genes_d[g]['Venters'].append('Fkh1')\n",
    "    if g in ostrow_Fkh1:\n",
    "        CC_genes_d[g]['Ostrow'].append('Fkh1')\n",
    "    if g in macIsaac_Fkh2:\n",
    "        CC_genes_d[g]['MacIsaac'].append('Fkh2')\n",
    "    if g in venters_Fkh2:\n",
    "        CC_genes_d[g]['Venters'].append('Fkh2')\n",
    "    if g in ostrow_Fkh2:\n",
    "        CC_genes_d[g]['Ostrow'].append('Fkh2')\n",
    "\n",
    "# print results\n",
    "for g in CC_genes_d:\n",
    "    print(g,'\\t\\t',{k:CC_genes_d[g][k] for k in CC_genes_d[g] if CC_genes_d[g][k] != []})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data to generate the central carbon metabolism image\n",
    "Here a slightly different approach: match substrings because there are many isoenzymes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CCm_genes_draft = ['HXT','HXK','GLK','PGI','PFK','FBP','FBA','GPD','GPP','GUT','TPI','TDH','ZWF','SOL','GND','RPE','RKI','TKL','TAL',\n",
    "                  'PGK','GPM','ENO','PCK','PYK','CDC19','PYC','PDC','ADH','ALD','LAT','PDX','PDB','PDA','ACS','IDH','IDP',\n",
    "                   'KGD','LSC','SDH','FUM','MDH','CIT','ACO']\n",
    "CCm_genes = []\n",
    "\n",
    "l = df[~df['Standard name'].isnull()]['Standard name'].values.tolist()\n",
    "for g in CCm_genes_draft:\n",
    "    for g2 in l:\n",
    "        if g in g2: #substring\n",
    "            CCm_genes.append(g2)\n",
    "\n",
    "CCm_genes_d = {g:{'MacIsaac':[],'Venters':[],'Ostrow':[],'This study':[]} for g in CCm_genes}\n",
    "\n",
    "\n",
    "# gather the results\n",
    "experiments = ['Fkh1 log','Fkh1 stat','Fkh2 log','Fkh2 stat']\n",
    "for i,exp in enumerate(experiments):\n",
    "    for g in CCm_genes:\n",
    "        if g in df_targets_list[i]['Standard name'].values.tolist():\n",
    "            CCm_genes_d[g]['This study'].append(exp)\n",
    "            \n",
    "# check the literature if each gene was shown before\n",
    "macIsaac_Fkh1 = df[df['MacIsaac 2006 Fkh1']]['Standard name'].values.tolist()\n",
    "venters_Fkh1 = df[df['Venters 2011 Fkh1']]['Standard name'].values.tolist()\n",
    "ostrow_Fkh1 = df[df['Ostrow 2014 Fkh1']]['Standard name'].values.tolist()    \n",
    "macIsaac_Fkh2 = df[df['MacIsaac 2006 Fkh2']]['Standard name'].values.tolist()\n",
    "venters_Fkh2 = df[df['Venters 2011 Fkh2']]['Standard name'].values.tolist()\n",
    "ostrow_Fkh2 = df[df['Ostrow 2014 Fkh2']]['Standard name'].values.tolist()   \n",
    "\n",
    "for g in CCm_genes:\n",
    "    if g in macIsaac_Fkh1:\n",
    "        CCm_genes_d[g]['MacIsaac'].append('Fkh1')\n",
    "    if g in venters_Fkh1:\n",
    "        CCm_genes_d[g]['Venters'].append('Fkh1')\n",
    "    if g in ostrow_Fkh1:\n",
    "        CCm_genes_d[g]['Ostrow'].append('Fkh1')\n",
    "    if g in macIsaac_Fkh2:\n",
    "        CCm_genes_d[g]['MacIsaac'].append('Fkh2')\n",
    "    if g in venters_Fkh2:\n",
    "        CCm_genes_d[g]['Venters'].append('Fkh2')\n",
    "    if g in ostrow_Fkh2:\n",
    "        CCm_genes_d[g]['Ostrow'].append('Fkh2')\n",
    "    \n",
    "# print results\n",
    "for g in CCm_genes_d:\n",
    "    print(g,'\\t\\t',{k:CCm_genes_d[g][k] for k in CCm_genes_d[g] if CCm_genes_d[g][k] != []})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noteworthy targets identified by only one method\n",
    "i.e. targets only picked up by one PDM sorted by score (showing the top 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['maxPeak_AD_12', 'GEM', 'MACE']\n",
    "colnames = [method + ' ' + exp for method in methods for exp in experiments]\n",
    "\n",
    "for i, exp in enumerate(experiments):\n",
    "    for method in methods:\n",
    "        col = method + ' ' + exp # target column name\n",
    "        print('######## '+col+' ########')\n",
    "        \n",
    "        # sort mace in ascending fashion\n",
    "        if method == 'MACE':\n",
    "            asc = True\n",
    "        else:\n",
    "            asc = False\n",
    "        \n",
    "        # sort targets on score\n",
    "        df = df.sort_values(col, ascending = asc)\n",
    "        \n",
    "        # find highest 5 scores that are ultimately not targets\n",
    "        genes_to_highlight = []\n",
    "        for gene, row in df.iterrows():\n",
    "            if gene not in df_targets_list[i].index:\n",
    "                genes_to_highlight.append(gene)\n",
    "                \n",
    "            if len(genes_to_highlight) == 5:\n",
    "                break\n",
    "                \n",
    "        display(df.loc[genes_to_highlight][['Standard name']+colnames])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank genes per method\n",
    "List the top 25 genes according to GEM ranking first and catalogue their ranking in MaxPeak and MACE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted_gem = df.sort_values('GEM Fkh1 log',ascending=False).iloc[:25]\n",
    "\n",
    "df_ranks = pd.DataFrame(index=df_sorted_gem.index)\n",
    "df_ranks['Standard name'] = df_sorted_gem['Standard name']\n",
    "df_ranks['MaxPeak'] = None\n",
    "df_ranks['MACE'] = None\n",
    "\n",
    "for g in df_sorted_gem.index.tolist():\n",
    "\n",
    "    df_ranks.at[g,'MaxPeak'] = df.sort_values('maxPeak_AD_12 Fkh1 log',ascending=False).index.get_loc(g)\n",
    "    df_ranks.at[g,'MACE'] = df.sort_values('MACE Fkh1 log',ascending=True).index.get_loc(g)\n",
    "\n",
    "df_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "692px",
    "left": "0px",
    "right": "1037px",
    "top": "111px",
    "width": "403px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
